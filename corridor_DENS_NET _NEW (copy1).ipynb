{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvrlab/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import re\n",
    "import hickle as hkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.legacy.nn import Reshape\n",
    "import graphviz\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#from visualize import make_dot\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "import time\n",
    "import logging\n",
    "from math import log,sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense161 = models.densenet161(pretrained=True)\n",
    "#dense161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense161\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeWeights(mod):\n",
    "    for m in mod.modules():\n",
    "        if isinstance(m,nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            #print m.weight.size(), m.out_channels, m.in_channels\n",
    "            m.weight.data.normal_(0,sqrt(2./n))\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.bias.data.zero_()    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Sequential(nn.BatchNorm2d(2208),nn.ReLU(),nn.Conv2d(2208,1024,1))\n",
    "conv1 = InitializeWeights(conv1)\n",
    "conv2 = nn.Sequential(nn.BatchNorm2d(1024),nn.ReLU(),nn.Conv2d(1024,128,5))\n",
    "conv2 = InitializeWeights(conv2)\n",
    "conv3 = nn.Sequential(nn.BatchNorm2d(128),nn.ReLU(),nn.Conv2d(128,16,1))\n",
    "conv3 = InitializeWeights(conv3)\n",
    "norm1 = nn.BatchNorm2d(16)\n",
    "norm1 = InitializeWeights(norm1)\n",
    "fc1 = nn.Linear(96, 1)\n",
    "fc1 = InitializeWeights(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel4(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(MyModel4, self).__init__()\n",
    "        self.pretrained_model = nn.Sequential(*list(dense161.children())[:-1])\n",
    "        self.conv1 = conv1\n",
    "        self.conv2 = conv2\n",
    "        self.conv3 = conv3\n",
    "        self.norm1 = norm1\n",
    "        self.fc1 = fc1\n",
    "   \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pretrained_model(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm1(x)\n",
    "        #print(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #print(x.size())\n",
    "        #x = self.conv4(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyModel4(dense161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "input=Variable(torch.randn(5,3,180,320))\n",
    "output=net(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "torch.Size([96, 3, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers --->  498\n",
      "Total number of parameters --->  32019857\n"
     ]
    }
   ],
   "source": [
    "sum1 = 0\n",
    "        \n",
    "print(\"Number of layers ---> \",len(list(net.parameters())))\n",
    "for params in net.parameters():\n",
    "    if params.requires_grad == True:\n",
    "        sum1 += params.numel()\n",
    "    \n",
    "print(\"Total number of parameters ---> \",sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.1739\n",
      " 0.4894\n",
      "-1.3829\n",
      "-0.4576\n",
      " 0.1522\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(5, 3, 180, 320))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('./DATASET/CODE/NewTrainData_59_cor__35000.h5')\n",
    "xtrainT = torch.from_numpy(np.array(file['xtrain'],dtype=np.float32)).float()\n",
    "ytrainT = torch.from_numpy(np.array(file['ytrain'],dtype=np.float32)).float()\n",
    "#xtrain = np.array(file['xtrain'],dtype=np.float32)\n",
    "#ytrain = np.array(file['ytrain'],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('./DATASET/CODE/NewTestData_22_cor_random_2.h5')\n",
    "xtestT = torch.from_numpy(np.array(file['xtest'],dtype=np.float32)).float()\n",
    "ytestT = torch.from_numpy(np.array(file['ytest'],dtype=np.float32)).float()\n",
    "#xtest = np.array(file['xtest'],dtype=np.float32)\n",
    "#ytest = np.array(file['ytest'],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_rgb_to_bgr(batch):\n",
    "    #print(batch.size())\n",
    "    (r, g, b) = torch.chunk(batch, 3, 1)\n",
    "    #print(r.size())\n",
    "    batch1 = torch.cat((b, g, r),1)\n",
    "    #print(batch1.size())\n",
    "    return batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35000, 3, 180, 320]) torch.Size([600, 3, 180, 320])\n"
     ]
    }
   ],
   "source": [
    "xtrainT = batch_rgb_to_bgr(xtrainT)\n",
    "xtestT = batch_rgb_to_bgr(xtestT)\n",
    "print(xtrainT.size(), xtestT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainT = torch.div(xtrainT,255.0)\n",
    "xtestT = torch.div(xtestT,255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.min(xtrainT), torch.max(xtrainT), torch.min(xtestT), torch.max(xtestT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrainT.size(), ytrainT.size(), xtestT.size(), ytestT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "    Normalize an tensor image with mean and standard deviation.\n",
    "    Given mean: (R, G, B) and std: (R, G, B),\n",
    "    will normalize each channel of the torch.*Tensor, i.e.\n",
    "    channel = (channel - mean) / std\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
    "        std (sequence): Sequence of standard deviations for R, G, B channels\n",
    "            respecitvely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn = [0.406,0.456,0.485]\n",
    "sd = [0.225,0.224,0.229]\n",
    "norm = Normalize(mn,sd)\n",
    "xtrainT = norm(xtrainT)\n",
    "xtestT = norm(xtestT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.min(xtrainT), torch.max(xtrainT), torch.min(xtestT), torch.max(xtestT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##def train(model, loss, optimizer, x_val, y_val, validPixel, batch_sz):\n",
    "def train(model, loss, optimizer, x_val, y_val,batch_size):\n",
    "    x = Variable(x_val,requires_grad = False).cuda()\n",
    "    y = Variable(y_val,requires_grad = False).cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    fx = model.forward(x)\n",
    "    \n",
    "    #print fx.data[0][0][64][87]\n",
    "    #fx = model5.forward(Variable(xtest2[start:end], volatile=True).cuda())\n",
    "    ##output = loss.forward(fx,y,validPixel,batch_sz)\n",
    "    output = loss.forward(fx,y)\n",
    "    #output = loss(fx, y)\n",
    "    output.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return output.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom loss function.... this will be reverse Huber...\n",
    "\n",
    "class CustomLoss1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self,inp, tar):\n",
    "        #target is the ground truth value...\n",
    "        #k = torch.mean(inp[:,0])\n",
    "        '''\n",
    "        if (k >= 1.48 and k <= 1.65):\n",
    "            diff = torch.abs(tar[:,1]-inp[:,1])\n",
    "            loss = torch.mean(torch.pow(diff,2))\n",
    "        else:\n",
    "        '''\n",
    "        diff = torch.abs(tar[:,0]-inp[:,0]) #*(180/np.pi)\n",
    "        loss = torch.mean(diff)\n",
    "        #print(loss)\n",
    "        return loss\n",
    "        '''\n",
    "        c1 = c.data[0] \n",
    "        temp = diff > c1\n",
    "        check1 = torch.prod(temp)\n",
    "        \n",
    "        if check1 == 0:\n",
    "            lossval = torch.mean(diff)\n",
    "        else:\n",
    "            temp4 = torch.pow(diff,2)\n",
    "            d = torch.pow(c,2)\n",
    "            temp4 = temp4.add(d.expand_as(temp4))\n",
    "            lossval = torch.mean(temp4/(2*c))\n",
    "        return lossval\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class BerhuLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BerhuLoss, self).__init__()\n",
    "        \n",
    "    def forward(self,inp, tar):\n",
    "        #target is the ground truth value...\n",
    "        mt = tar[:,0]\n",
    "        mp = inp[:,0]\n",
    "        diff = torch.abs(mt-mp)        \n",
    "        lossval = 0.0        \n",
    "        c = 0.2 * torch.max(diff)\n",
    "        l1 = torch.mean(diff)\n",
    "        l2 = torch.mean(torch.pow(diff,2))\n",
    "        if l1 <= c:\n",
    "            lossval = l1\n",
    "        else:\n",
    "            lossval = (l2+c**2)/(2*c)\n",
    "        \n",
    "        return lossval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom loss function.... this will be reverse Huber...\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self,inp, tar):\n",
    "        #target is the ground truth value...\n",
    "        #k = torch.mean(inp[:,0])\n",
    "        '''\n",
    "        if (k >= 1.48 and k <= 1.65):\n",
    "            diff = torch.abs(tar[:,1]-inp[:,1])\n",
    "            loss = torch.mean(torch.pow(diff,2))\n",
    "        else:\n",
    "        '''\n",
    "        diff = torch.abs(tar[:,0]-inp[:,0]) #*(180/np.pi)\n",
    "        loss = torch.mean(torch.pow(diff,2))\n",
    "        #print(loss)\n",
    "        return loss\n",
    "        '''\n",
    "        c1 = c.data[0] \n",
    "        temp = diff > c1\n",
    "        check1 = torch.prod(temp)\n",
    "        \n",
    "        if check1 == 0:\n",
    "            lossval = torch.mean(diff)\n",
    "        else:\n",
    "            temp4 = torch.pow(diff,2)\n",
    "            d = torch.pow(c,2)\n",
    "            temp4 = temp4.add(d.expand_as(temp4))\n",
    "            lossval = torch.mean(temp4/(2*c))\n",
    "        return lossval\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha = torch.FloatTensor(ytrainT[5,0])\n",
    "alpha = ytrainT[5,0]\n",
    "#print(alpha.shape)\n",
    "xt = torch.FloatTensor([np.cos(alpha),np.sin(alpha)])\n",
    "print(ytrainT[5,0],xt.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = ytrainT[5:10,0]\n",
    "print(torch.cos(alpha[0:1]-alpha[1:2]))\n",
    "xt = torch.stack([torch.cos(alpha[0:1]),torch.sin(alpha[0:1])])\n",
    "xp = torch.stack([torch.cos(alpha[1:2]),torch.sin(alpha[1:2])])\n",
    "print(xt[0],xt[1])\n",
    "#print(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CosineLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineLoss, self).__init__()\n",
    "        \n",
    "    def forward(self,inp, tar,batch_sz):\n",
    "        alpha_t = tar[:,0]\n",
    "        alpha_p = inp[:,0]\n",
    "        #xt = torch.stack([torch.cos(alpha_t),torch.sin(alpha_t)])\n",
    "        #xp = torch.stack([torch.cos(alpha_p),torch.sin(alpha_p)])\n",
    "        #cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        #loss = cos(xt, xp)\n",
    "        #return loss\n",
    "        loss = Variable(torch.FloatTensor(batch_sz).zero_(), requires_grad=False).cuda()\n",
    "        for i in range(batch_sz):          \n",
    "            loss[i] = torch.cos(alpha_t[i:i+1]-alpha_p[i:i+1])\n",
    "            \n",
    "        lossval = 1.0-torch.mean(loss)    \n",
    "        #print(lossval)\n",
    "        return lossval\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "er=np.zeros((1,10))\n",
    "print(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MUST UNCOMMENT BELOW LINE...\n",
    "    \n",
    "net = net.cuda()\n",
    "\n",
    "#loading the model after the weights of epoch50.. to check what loss the model gives if lr is taken as 0.0001\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#criterion = RMSELoss()\n",
    "#criterion = BerhuLoss()\n",
    "#criterion = EuclideanLoss()\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = CosineLoss()\n",
    "#criterion = torch.nn.MSELoss(size_average=False)\n",
    "criterion = CustomLoss()\n",
    "#criterion = BerhuLoss()\n",
    "#criterion = CosineLoss()\n",
    "criterion.cuda()\n",
    "\n",
    "currepochloss =float('Inf')\n",
    "#epochs, n_examples, i, batch_size, flag = 1,5900, 0, 5, 0\n",
    "epochs, n_examples, i, batch_size, flag = 3, 35000, 0, 30, 0\n",
    "er=np.zeros((1,epochs))\n",
    "\n",
    "while i != epochs:\n",
    "    since = time.time()\n",
    "    cost, batchloss = 0.0, 0.0\n",
    "    num_batches = n_examples//batch_size\n",
    "    #print num_batches    #indices = np.random.permutation(5600)\n",
    "    #indices = np.random.permutation(3524)\n",
    "    \n",
    "    #indices = np.random.permutation(5900)\n",
    "    indices = np.random.permutation(n_examples)\n",
    "    samplesUnprocessed = np.size(indices)\n",
    "    \n",
    "    #batchwise training starts here...\n",
    "    for k in range(num_batches):\n",
    "        since1 = time.time()\n",
    "       # print(\"bacth number:\"+str(k))\n",
    "        xtrain3 = torch.FloatTensor(batch_size,3,180,320)\n",
    "        ytrain3 = torch.FloatTensor(batch_size,1)\n",
    "        ##validPixel = torch.FloatTensor(batch_size,480,640)\n",
    "        \n",
    "        for ind in range(batch_size):\n",
    "            #ind1 = np.random.randint(0,5599)\n",
    "            ind1 = np.random.randint(0,samplesUnprocessed)\n",
    "            #ind1 = np.random.randint(0,794)\n",
    "            #ind1 = np.random.randint(0,794)            \n",
    "            newxind = indices[ind1]            \n",
    "            xtrain3[ind] = xtrainT[newxind]\n",
    "            ytrain3[ind] = ytrainT[newxind,0,0]\n",
    "            ##validPixel[ind] = imgValidTrain2[newxind]\n",
    "            \n",
    "            #print ytrain3[ind,0,0,0], ytrain2[newxind,0,0,0]\n",
    "            indices = np.delete(indices,ind1)\n",
    "            samplesUnprocessed = samplesUnprocessed - 1\n",
    "        \n",
    "        #start, end = k*batch_size, (k+1)*batch_size\n",
    "        #batchloss = train(model5,criterion, optimizer, xtrain3, ytrain3, validPixel,batch_size)\n",
    "        batchloss = train(net,criterion, optimizer, xtrain3, ytrain3, batch_size)\n",
    "        batch_time = time.time() - since1\n",
    "        #cost += batchloss\n",
    "        cost = (cost*k+batchloss)/(k+1)\n",
    "        #print k,cost\n",
    "        #print(\"No. of samples UnProcessed \"+str(samplesUnprocessed))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    epochloss = cost #/num_batches\n",
    "    er[1,i]=epochloss\n",
    "    \n",
    "    if epochloss < currepochloss:\n",
    "        print('save the weights')\n",
    "        torch.save(net.state_dict(),\"./weights/customloss/new/CustomLoss_35000_DISTANCE_3_epochs.pth\")\n",
    "        flag = 0\n",
    "        currepochloss = epochloss\n",
    "    else:\n",
    "        flag += 1\n",
    "        \n",
    "        if flag == 5:\n",
    "            for p in optimizer.param_groups:\n",
    "                lr2 = p['lr']\n",
    "            newlr = lr2/5\n",
    "            \n",
    "            if newlr < 1e-15:\n",
    "                print(\"Cant decrease further!!\")\n",
    "                newlr = 1e-15\n",
    "            flag = 0 \n",
    "            optimizer = optim.SGD(net.parameters(), lr=newlr, momentum=0.9)\n",
    "            print(\"Learning rate changed from \"+str(lr2)+\" to \"+str(newlr))\n",
    "            \n",
    "        print(\"Loss \"+str(epochloss)+\" is bigger than Loss \"+str(currepochloss)+\" in the prev epoch \")\n",
    "        \n",
    "    print('Loss = {:.8f} at epoch {:d} completed in {:.0f}m {:.0f}s'.format(epochloss,(i+1),(time_elapsed//60),(time_elapsed%60)))\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"er.csv\", er, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for params in optimizer.param_groups:\n",
    "    print(params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = net.cuda()\n",
    "net.load_state_dict(torch.load(\"./weights/CustomLoss_new/CustomLoss_new_35000_107_epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing of the architecture...\n",
    "num_batches = 0\n",
    "#6 evenly divides the test batch size..\n",
    "test_batch_size = 20\n",
    "n_examples = 600\n",
    "#finalpred = Variable(torch.zeros((n_examples,3,120,160)))\n",
    "finalpred = Variable(torch.zeros((n_examples,1)))\n",
    "print(\"finalpred size is ---> \", finalpred.size())\n",
    "\n",
    "num_batches = n_examples//test_batch_size\n",
    "print(\"num of batches --->\", num_batches)\n",
    "for k in range(num_batches):\n",
    "    start, end = k*test_batch_size, (k+1)*test_batch_size\n",
    "    output = net.forward(Variable(xtestT[start:end], volatile=True).cuda())\n",
    "    finalpred[start:end] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = finalpred.data.numpy()\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dif = torch.abs(finalpred.data[:,0]-ytestT[:,0,0])\n",
    "print(dif.size())\n",
    "np.savetxt(\"diff.csv\", dif.numpy(), delimiter=\",\")\n",
    "MSEloss = torch.mean(torch.pow(dif,2))\n",
    "ABSlossRad = torch.mean(dif)\n",
    "ABSlossDeg = ABSlossRad*(180/np.pi)\n",
    "print(\"MSEloss==\"+str(MSEloss),\"ABSlossRad==\"+str(ABSlossRad),\"ABSlossDeg\"+str(ABSlossDeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(finalpred.size())\n",
    "print(ytestT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(9)\n",
    "fig.set_figwidth(9)\n",
    "import cv2\n",
    "\n",
    "ind = 143\n",
    "testPT = xtestT[ind]\n",
    "print(\"Actual angle===\"+str(ytestT[ind,0,0]*(180/np.pi)))\n",
    "testPT = testPT.view(1,3,180,320)\n",
    "test_pred = net.forward(Variable(testPT, volatile=True).cuda())\n",
    "print(\"Pred angle===\"+str(finalpred.data[ind,0]*(180/np.pi)))\n",
    "testx = testPT.numpy()\n",
    "testx = np.reshape(testx,(3,180,320))\n",
    "testx = testx.transpose(1,2,0)\n",
    "testx = imresize(testx,(180,320,3))\n",
    "#imshow(testx)\n",
    "scipy.misc.imsave('test.png', testx)\n",
    "a=fig.add_subplot(1,2,1)\n",
    "imgplot = plt.imshow(testx)\n",
    "a.set_title('Input')\n",
    "a.axes.get_xaxis().set_visible(False)\n",
    "a.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "#print(finalpred.data[n,0]*(180/np.pi))\n",
    "#print(ytestT[ind,0,0]*(180/np.pi))\n",
    "print(ytestT[ind,0,0]*(180/np.pi)-finalpred.data[ind,0]*(180/np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ABSlossRad*(180/np.pi))\n",
    "print(MSEloss*(180/np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(ytestT[:,0]*(180/np.pi))\n",
    "#print(ytestT[:,0,2]*(180/np.pi))\n",
    "a = ytestT[:,0,0]*(180/np.pi)\n",
    "print(a.size())\n",
    "np.savetxt(\"test.csv\", a.numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = np.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "#np.savetxt(\"foo.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(finalpred.data[:,0]*(180/np.pi))\n",
    "print(finalpred.data[:,0]*(180/np.pi))\n",
    "b = finalpred.data[:,0]*(180/np.pi)\n",
    "c=torch.abs(ytestT[:,0,0]*(180/np.pi)- finalpred.data[:,0]*(180/np.pi))\n",
    "np.savetxt(\"pred.csv\", b.numpy(), delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"diff.csv\", c.numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalpred.data[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(9)\n",
    "fig.set_figwidth(9)\n",
    "import cv2\n",
    "\n",
    "test = cv2.imread(\"./Test_Net_image/4.JPG\")\n",
    "print(test.shape)\n",
    "test = imresize(test,(180,320,3))\n",
    "#imshow(test)\n",
    "test = test.transpose(2,0,1)\n",
    "test = np.reshape(test,(1,3,180,320))\n",
    "test = test.astype(np.float32)\n",
    "testPT = torch.from_numpy(test).float()\n",
    "testPT = batch_rgb_to_bgr(testPT)\n",
    "testPT = torch.div(testPT,255.0)\n",
    "mn = [0.406,0.456,0.485]\n",
    "sd = [0.225,0.224,0.229]\n",
    "norm = Normalize(mn,sd)\n",
    "testPT = norm(testPT)\n",
    "'''\n",
    "ind = 2000\n",
    "testPT = xtestT[ind]\n",
    "print(\"Actual angle===\"+str(ytestT[ind,0]*(180/np.pi)), ytestT[ind,0])\n",
    "testPT = testPT.view(1,3,180,320)\n",
    "#'''\n",
    "test_pred = net.forward(Variable(testPT, volatile=True).cuda())\n",
    "print(\"Angle===\"+str(test_pred.data[0,0]*(180/np.pi)), test_pred.data[0,0])\n",
    "testx = testPT.numpy()\n",
    "testx = np.reshape(testx,(3,180,320))\n",
    "testx = testx.transpose(1,2,0)\n",
    "testx = imresize(testx,(180,320,3))\n",
    "#imshow(testx)\n",
    "scipy.misc.imsave('test.png', testx)\n",
    "a=fig.add_subplot(1,2,1)\n",
    "imgplot = plt.imshow(testx)\n",
    "a.set_title('Input')\n",
    "a.axes.get_xaxis().set_visible(False)\n",
    "a.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
