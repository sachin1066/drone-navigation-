{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import re\n",
    "import hickle as hkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.legacy.nn import Reshape\n",
    "import graphviz\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#from visualize import make_dot\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "import time\n",
    "import logging\n",
    "from math import log,sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense161 = models.densenet161(pretrained=True)\n",
    "#dense161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense161\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def InitializeWeights(mod):\n",
    "    for m in mod.modules():\n",
    "        if isinstance(m,nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            #print m.weight.size(), m.out_channels, m.in_channels\n",
    "            m.weight.data.normal_(0,sqrt(2./n))\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel4 (\n",
      "  (pretrained_model): Sequential (\n",
      "    (0): Sequential (\n",
      "      (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu0): ReLU (inplace)\n",
      "      (pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "      (denseblock1): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition1): _Transition (\n",
      "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d (\n",
      "        )\n",
      "      )\n",
      "      (denseblock2): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition2): _Transition (\n",
      "        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d (\n",
      "        )\n",
      "      )\n",
      "      (denseblock3): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer25): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer26): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer27): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer28): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer29): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer30): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer31): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer32): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer33): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer34): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer35): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer36): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (transition3): _Transition (\n",
      "        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu): ReLU (inplace)\n",
      "        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (pool): AvgPool2d (\n",
      "        )\n",
      "      )\n",
      "      (denseblock4): _DenseBlock (\n",
      "        (denselayer1): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer2): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer3): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer4): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer5): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer6): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer7): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer8): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer9): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer10): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer11): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer12): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer13): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer14): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer15): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer16): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer17): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer18): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer19): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer20): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer21): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer22): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer23): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (denselayer24): _DenseLayer (\n",
      "          (norm.1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.1): ReLU (inplace)\n",
      "          (conv.1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "          (relu.2): ReLU (inplace)\n",
      "          (conv.2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(2208, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(1024, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc1): Linear (96 -> 1)\n",
      "  (bnorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (bnorm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel4(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(MyModel4, self).__init__()\n",
    "        self.pretrained_model = nn.Sequential(*list(dense161.children())[:-1])\n",
    "\n",
    "        #self.unpool1 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        #self.unpool2 = nn.UpsamplingBilinear2d(size=(60,80))\n",
    "        #self.conv0 = nn.Conv2d(2208,1024,1)\n",
    "        ##self.conv1 = nn.Conv2d(1024,512,1)\n",
    "        self.conv1 = InitializeWeights(nn.Conv2d(2208,1024,1))\n",
    "        self.conv2 = InitializeWeights(nn.Conv2d(1024,128,5))\n",
    "        self.conv3 = InitializeWeights(nn.Conv2d(128,16,1))\n",
    "        self.fc1 = nn.Linear(96, 1)\n",
    "       # self.conv2 = nn.Conv2d(512,256,5,padding=(2,2))\n",
    "        #self.conv3 = nn.Conv2d(256,128,5,padding=(4,2))\n",
    "        #self.conv4 = nn.Conv2d(128,1,3,padding=(1,1))\n",
    "       # #self.conv5 = nn.Conv2d(128,1,3,padding=(1,1))\n",
    "        self.bnorm1 = InitializeWeights(nn.BatchNorm2d(1024))\n",
    "        self.bnorm2 = InitializeWeights(nn.BatchNorm2d(128))\n",
    "        self.bnorm3 = InitializeWeights(nn.BatchNorm2d(16))\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "    def unpool_conv(self,inp1,conv,unpool):\n",
    "        #x = inp1\n",
    "        x = unpool(inp1)\n",
    "        x = F.relu(conv(x))\n",
    "        return x\n",
    "    \n",
    "    #below for testing purpose only...\n",
    "    def unpool_conv1(self,inp1,conv,unpool):\n",
    "        x = inp1\n",
    "        #x = unpool(inp1)\n",
    "        x = F.relu(conv(x))\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pretrained_model(x))\n",
    "        x=F.relu(self.bnorm1(self.conv1(x)))\n",
    "        x=F.relu(self.bnorm2(self.conv2(x)))\n",
    "        x=F.relu(self.bnorm3(self.conv3(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        \n",
    "        #x = self.conv0(x)\n",
    "        #x = self.bnorm(x)\n",
    "       # x = self.unpool_conv(x,self.conv1,self.unpool1)\n",
    "       # x = self.unpool_conv(x,self.conv2,self.unpool1)\n",
    "        #x = self.unpool_conv(x,self.conv3,self.unpool1)\n",
    "       # #x = self.unpool_conv(x,self.conv4,self.unpool2)\n",
    "       # #x = self.unpool2(x)\n",
    "        #x = self.conv4(x)\n",
    "        #x = x.view(-1,60,80)\n",
    "        \n",
    "        return x\n",
    "net = MyModel4(dense161)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model4 = MyModel4(dense161)\n",
    "#model4.forward(Variable(torch.randn(2,3,240,320))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "input=Variable(torch.randn(1,3,180,320))\n",
    "output=net(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "torch.Size([96, 3, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers --->  496\n",
      "Total number of parameters --->  32015441\n"
     ]
    }
   ],
   "source": [
    "sum1 = 0\n",
    "        \n",
    "print(\"Number of layers ---> \",len(list(net.parameters())))\n",
    "for params in net.parameters():\n",
    "    if params.requires_grad == True:\n",
    "        sum1 += params.numel()\n",
    "    \n",
    "print(\"Total number of parameters ---> \",sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0000\n",
      " 0.0000\n",
      " 0.3854\n",
      " 0.3434\n",
      " 0.0000\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(5, 3, 180, 320))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = h5py.File('./DATASET/CODE/NewTrainData.h5')\n",
    "xtrainT = torch.from_numpy(np.array(file['xtrain'],dtype=np.float32)).float()\n",
    "ytrainT = torch.from_numpy(np.array(file['ytrain'],dtype=np.float32)).float()\n",
    "#xtrain = np.array(file['xtrain'],dtype=np.float32)\n",
    "#ytrain = np.array(file['ytrain'],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = h5py.File('./DATASET/CODE/NewTestData.h5')\n",
    "xtestT = torch.from_numpy(np.array(file['xtest'],dtype=np.float32)).float()\n",
    "ytestT = torch.from_numpy(np.array(file['ytest'],dtype=np.float32)).float()\n",
    "#xtest = np.array(file['xtest'],dtype=np.float32)\n",
    "#ytest = np.array(file['ytest'],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_rgb_to_bgr(batch):\n",
    "    #print(batch.size())\n",
    "    (r, g, b) = torch.chunk(batch, 3, 1)\n",
    "    #print(r.size())\n",
    "    batch1 = torch.cat((b, g, r),1)\n",
    "    #print(batch1.size())\n",
    "    return batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20100, 3, 180, 320]) torch.Size([1560, 3, 180, 320])\n"
     ]
    }
   ],
   "source": [
    "xtrainT = batch_rgb_to_bgr(xtrainT)\n",
    "xtestT = batch_rgb_to_bgr(xtestT)\n",
    "print(xtrainT.size(), xtestT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrainT = torch.div(xtrainT,255.0)\n",
    "xtestT = torch.div(xtestT,255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(xtrainT), torch.max(xtrainT), torch.min(xtestT), torch.max(xtestT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20100, 3, 180, 320]) torch.Size([20100, 2, 3]) torch.Size([1560, 3, 180, 320]) torch.Size([1560, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(xtrainT.size(), ytrainT.size(), xtestT.size(), ytestT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "    Normalize an tensor image with mean and standard deviation.\n",
    "    Given mean: (R, G, B) and std: (R, G, B),\n",
    "    will normalize each channel of the torch.*Tensor, i.e.\n",
    "    channel = (channel - mean) / std\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
    "        std (sequence): Sequence of standard deviations for R, G, B channels\n",
    "            respecitvely.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        # TODO: make efficient\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn = [0.406,0.456,0.485]\n",
    "sd = [0.225,0.224,0.229]\n",
    "norm = Normalize(mn,sd)\n",
    "xtrainT = norm(xtrainT)\n",
    "xtestT = norm(xtestT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1179039478302 2.640000104904175 -2.1007792949676514 2.640000104904175\n"
     ]
    }
   ],
   "source": [
    "print(torch.min(xtrainT), torch.max(xtrainT), torch.min(xtestT), torch.max(xtestT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##def train(model, loss, optimizer, x_val, y_val, validPixel, batch_sz):\n",
    "def train(model, loss, optimizer, x_val, y_val,batch_size):\n",
    "    x = Variable(x_val,requires_grad = False).cuda()\n",
    "    y = Variable(y_val,requires_grad = False).cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    fx = model.forward(x)\n",
    "    \n",
    "    #print fx.data[0][0][64][87]\n",
    "    #fx = model5.forward(Variable(xtest2[start:end], volatile=True).cuda())\n",
    "    ##output = loss.forward(fx,y,validPixel,batch_sz)\n",
    "    output = loss.forward(fx,y)\n",
    "    #output = loss(fx, y)\n",
    "    output.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return output.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom loss function.... this will be reverse Huber...\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "    def forward(self,inp, tar):\n",
    "        #target is the ground truth value...\n",
    "        #k = torch.mean(inp[:,0])\n",
    "        '''\n",
    "        if (k >= 1.48 and k <= 1.65):\n",
    "            diff = torch.abs(tar[:,1]-inp[:,1])\n",
    "            loss = torch.mean(torch.pow(diff,2))\n",
    "        else:\n",
    "        '''\n",
    "        diff = torch.abs(tar[:,0]-inp[:,0]) #*(180/np.pi)\n",
    "        loss = torch.mean(torch.pow(diff,2))\n",
    "        #print(loss)\n",
    "        return loss\n",
    "        '''\n",
    "        c1 = c.data[0] \n",
    "        temp = diff > c1\n",
    "        check1 = torch.prod(temp)\n",
    "        \n",
    "        if check1 == 0:\n",
    "            lossval = torch.mean(diff)\n",
    "        else:\n",
    "            temp4 = torch.pow(diff,2)\n",
    "            d = torch.pow(c,2)\n",
    "            temp4 = temp4.add(d.expand_as(temp4))\n",
    "            lossval = torch.mean(temp4/(2*c))\n",
    "        return lossval\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha = torch.FloatTensor(ytrainT[5,0])\n",
    "alpha = ytrainT[5,0]\n",
    "#print(alpha.shape)\n",
    "xt = torch.FloatTensor([np.cos(alpha),np.sin(alpha)])\n",
    "print(ytrainT[5,0],xt.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = ytrainT[5:10,0]\n",
    "print(torch.cos(alpha[0:1]-alpha[1:2]))\n",
    "xt = torch.stack([torch.cos(alpha[0:1]),torch.sin(alpha[0:1])])\n",
    "xp = torch.stack([torch.cos(alpha[1:2]),torch.sin(alpha[1:2])])\n",
    "print(xt[0],xt[1])\n",
    "#print(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CosineLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CosineLoss, self).__init__()\n",
    "        \n",
    "    def forward(self,inp, tar,batch_sz):\n",
    "        alpha_t = tar[:,0]\n",
    "        alpha_p = inp[:,0]\n",
    "        #xt = torch.stack([torch.cos(alpha_t),torch.sin(alpha_t)])\n",
    "        #xp = torch.stack([torch.cos(alpha_p),torch.sin(alpha_p)])\n",
    "        #cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        #loss = cos(xt, xp)\n",
    "        #return loss\n",
    "        loss = Variable(torch.FloatTensor(batch_sz).zero_(), requires_grad=False).cuda()\n",
    "        for i in range(batch_sz):          \n",
    "            loss[i] = torch.cos(alpha_t[i:i+1]-alpha_p[i:i+1])\n",
    "            \n",
    "        lossval = 1.0-torch.mean(loss)    \n",
    "        #print(lossval)\n",
    "        return lossval\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the weights\n",
      "Loss = 0.0009 at epoch 1 completed in 5m 38s\n",
      "save the weights\n",
      "Loss = 0.0008 at epoch 2 completed in 5m 37s\n",
      "save the weights\n",
      "Loss = 0.0008 at epoch 3 completed in 5m 36s\n",
      "Loss 0.0008059579322597624 is bigger than Loss 0.0007978266254918822 in the prev epoch \n",
      "Loss = 0.0008 at epoch 4 completed in 5m 36s\n",
      "Loss 0.0008095861585035838 is bigger than Loss 0.0007978266254918822 in the prev epoch \n",
      "Loss = 0.0008 at epoch 5 completed in 5m 36s\n",
      "save the weights\n",
      "Loss = 0.0008 at epoch 6 completed in 5m 36s\n",
      "save the weights\n",
      "Loss = 0.0008 at epoch 7 completed in 5m 35s\n",
      "Loss 0.000767983400711178 is bigger than Loss 0.000753809817468943 in the prev epoch \n",
      "Loss = 0.0008 at epoch 8 completed in 5m 36s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 9 completed in 5m 37s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 10 completed in 5m 36s\n",
      "Loss 0.0007128380682951869 is bigger than Loss 0.0007104015236054964 in the prev epoch \n",
      "Loss = 0.0007 at epoch 11 completed in 5m 36s\n",
      "Loss 0.0007187172223608795 is bigger than Loss 0.0007104015236054964 in the prev epoch \n",
      "Loss = 0.0007 at epoch 12 completed in 5m 36s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 13 completed in 5m 40s\n",
      "Loss 0.0007067944852325988 is bigger than Loss 0.0006919923619629553 in the prev epoch \n",
      "Loss = 0.0007 at epoch 14 completed in 5m 55s\n",
      "Loss 0.0006931840241869302 is bigger than Loss 0.0006919923619629553 in the prev epoch \n",
      "Loss = 0.0007 at epoch 15 completed in 5m 37s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 16 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 17 completed in 5m 35s\n",
      "Loss 0.00067484772928344 is bigger than Loss 0.0006661502405942016 in the prev epoch \n",
      "Loss = 0.0007 at epoch 18 completed in 5m 35s\n",
      "Loss 0.0006679388954662094 is bigger than Loss 0.0006661502405942016 in the prev epoch \n",
      "Loss = 0.0007 at epoch 19 completed in 5m 36s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 20 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 21 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0007 at epoch 22 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0006 at epoch 23 completed in 5m 35s\n",
      "Loss 0.0006370235060744763 is bigger than Loss 0.0006268242028726048 in the prev epoch \n",
      "Loss = 0.0006 at epoch 24 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0006 at epoch 25 completed in 5m 35s\n",
      "Loss 0.000614171555164138 is bigger than Loss 0.0006079135009794803 in the prev epoch \n",
      "Loss = 0.0006 at epoch 26 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0006 at epoch 27 completed in 5m 35s\n",
      "Loss 0.0006077402745462161 is bigger than Loss 0.0006020728526715147 in the prev epoch \n",
      "Loss = 0.0006 at epoch 28 completed in 5m 35s\n",
      "Loss 0.0006040368495863488 is bigger than Loss 0.0006020728526715147 in the prev epoch \n",
      "Loss = 0.0006 at epoch 29 completed in 5m 35s\n",
      "save the weights\n",
      "Loss = 0.0006 at epoch 30 completed in 5m 35s\n"
     ]
    }
   ],
   "source": [
    "#MUST UNCOMMENT BELOW LINE...\n",
    "    \n",
    "net = net.cuda()\n",
    "\n",
    "#loading the model after the weights of epoch50.. to check what loss the model gives if lr is taken as 0.0001\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#criterion = RMSELoss()\n",
    "#criterion = BerhuLoss()\n",
    "#criterion = EuclideanLoss()\n",
    "#criterion = nn.MSELoss()\n",
    "#criterion = CosineLoss()\n",
    "#criterion = torch.nn.MSELoss(size_average=False)\n",
    "criterion = CustomLoss()\n",
    "#criterion = CosineLoss()\n",
    "criterion.cuda()\n",
    "\n",
    "currepochloss = float('Inf')\n",
    "#epochs, n_examples, i, batch_size, flag = 1,5900, 0, 5, 0\n",
    "epochs, n_examples, i, batch_size, flag = 30, 20100, 0, 30, 0\n",
    "\n",
    "\n",
    "while i != epochs:\n",
    "    since = time.time()\n",
    "    cost, batchloss = 0.0, 0.0\n",
    "    num_batches = n_examples//batch_size\n",
    "    #print num_batches    #indices = np.random.permutation(5600)\n",
    "    #indices = np.random.permutation(3524)\n",
    "    \n",
    "    #indices = np.random.permutation(5900)\n",
    "    indices = np.random.permutation(n_examples)\n",
    "    samplesUnprocessed = np.size(indices)\n",
    "    \n",
    "    #batchwise training starts here...\n",
    "    for k in range(num_batches):\n",
    "        since1 = time.time()\n",
    "       # print(\"bacth number:\"+str(k))\n",
    "        xtrain3 = torch.FloatTensor(batch_size,3,180,320)\n",
    "        ytrain3 = torch.FloatTensor(batch_size,1)\n",
    "        ##validPixel = torch.FloatTensor(batch_size,480,640)\n",
    "        \n",
    "        for ind in range(batch_size):\n",
    "            #ind1 = np.random.randint(0,5599)\n",
    "            ind1 = np.random.randint(0,samplesUnprocessed)\n",
    "            #ind1 = np.random.randint(0,794)\n",
    "            #ind1 = np.random.randint(0,794)            \n",
    "            newxind = indices[ind1]            \n",
    "            xtrain3[ind] = xtrainT[newxind]\n",
    "            ytrain3[ind] = ytrainT[newxind,0,2]\n",
    "            ##validPixel[ind] = imgValidTrain2[newxind]\n",
    "            \n",
    "            #print ytrain3[ind,0,0,0], ytrain2[newxind,0,0,0]\n",
    "            indices = np.delete(indices,ind1)\n",
    "            samplesUnprocessed = samplesUnprocessed - 1\n",
    "        \n",
    "        #start, end = k*batch_size, (k+1)*batch_size\n",
    "        #batchloss = train(model5,criterion, optimizer, xtrain3, ytrain3, validPixel,batch_size)\n",
    "        batchloss = train(net,criterion, optimizer, xtrain3, ytrain3, batch_size)\n",
    "        batch_time = time.time() - since1\n",
    "        #cost += batchloss\n",
    "        cost = (cost*k+batchloss)/(k+1)\n",
    "        #print k,cost\n",
    "        #print(\"No. of samples UnProcessed \"+str(samplesUnprocessed))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    epochloss = cost #/num_batches\n",
    "    \n",
    "    if epochloss < currepochloss:\n",
    "        print('save the weights')\n",
    "        torch.save(net.state_dict(),\"./weights/customloss/customloss_20100_77_epochs.pth\")\n",
    "        flag = 0\n",
    "        currepochloss = epochloss\n",
    "    else:\n",
    "        flag += 1\n",
    "        \n",
    "        if flag == 5:\n",
    "            for p in optimizer.param_groups:\n",
    "                lr2 = p['lr']\n",
    "            newlr = lr2/5\n",
    "            \n",
    "            if newlr < 1e-15:\n",
    "                print(\"Cant decrease further!!\")\n",
    "                newlr = 1e-15\n",
    "            flag = 0 \n",
    "            optimizer = optim.SGD(net.parameters(), lr=newlr, momentum=0.9)\n",
    "            print(\"Learning rate changed from \"+str(lr2)+\" to \"+str(newlr))\n",
    "            \n",
    "        print(\"Loss \"+str(epochloss)+\" is bigger than Loss \"+str(currepochloss)+\" in the prev epoch \")\n",
    "        \n",
    "    print('Loss = {:.8f} at epoch {:d} completed in {:.0f}m {:.0f}s'.format(epochloss,(i+1),(time_elapsed//60),(time_elapsed%60)))\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for params in optimizer.param_groups:\n",
    "    print(params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = net.cuda()\n",
    "#net.load_state_dict(torch.load(\"./weights/corridor_new_data_bgr_600.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalpred size is --->  torch.Size([1560, 1])\n",
      "num of batches ---> 156\n"
     ]
    }
   ],
   "source": [
    "#testing of the architecture...\n",
    "num_batches = 0\n",
    "#6 evenly divides the test batch size..\n",
    "test_batch_size = 10\n",
    "n_examples = 1560\n",
    "#finalpred = Variable(torch.zeros((n_examples,3,120,160)))\n",
    "finalpred = Variable(torch.zeros((n_examples,1)))\n",
    "print(\"finalpred size is ---> \", finalpred.size())\n",
    "\n",
    "num_batches = n_examples//test_batch_size\n",
    "print(\"num of batches --->\", num_batches)\n",
    "for k in range(num_batches):\n",
    "    start, end = k*test_batch_size, (k+1)*test_batch_size\n",
    "    output = net.forward(Variable(xtestT[start:end], volatile=True).cuda())\n",
    "    finalpred[start:end] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1560, 1)\n"
     ]
    }
   ],
   "source": [
    "data1 = finalpred.data.numpy()\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1560])\n",
      "MSEloss==0.06294170056023544 ABSloss==0.19798365151270841\n"
     ]
    }
   ],
   "source": [
    "dif = torch.abs(finalpred.data[:,0]-ytestT[:,0,2])\n",
    "print(dif.size())\n",
    "np.savetxt(\"diff.csv\", dif.numpy(), delimiter=\",\")\n",
    "MSEloss = torch.mean(torch.pow(dif,2))\n",
    "ABSloss = torch.mean(dif)\n",
    "print(\"MSEloss==\"+str(MSEloss),\"ABSloss==\"+str(ABSloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1560, 1])\n",
      "torch.Size([1560, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(finalpred.size())\n",
    "print(ytestT.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.69681090555285\n",
      "45.00000125223908\n",
      "-21.69680965331377\n"
     ]
    }
   ],
   "source": [
    "n=452\n",
    "\n",
    "print(finalpred.data[n,0]*(180/np.pi))\n",
    "print(ytestT[n,0,2]*(180/np.pi))\n",
    "print(ytestT[n,0,2]*(180/np.pi)-finalpred.data[n,0]*(180/np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.34362764426707\n",
      "3.6062937974777003\n"
     ]
    }
   ],
   "source": [
    "print(ABSloss*(180/np.pi))\n",
    "print(MSEloss*(180/np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1560])\n"
     ]
    }
   ],
   "source": [
    "#print(ytestT[:,0]*(180/np.pi))\n",
    "#print(ytestT[:,0,2]*(180/np.pi))\n",
    "a = ytestT[:,0,2]*(180/np.pi)\n",
    "print(a.size())\n",
    "np.savetxt(\"test.csv\", a.numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = np.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "#np.savetxt(\"foo.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 100.4519\n",
      "  89.1286\n",
      "  97.5042\n",
      "        \n",
      "  63.6057\n",
      " 128.7775\n",
      "  66.1512\n",
      "[torch.FloatTensor of size 1560]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(finalpred.data[:,0]*(180/np.pi))\n",
    "print(finalpred.data[:,0]*(180/np.pi))\n",
    "b = finalpred.data[:,0]*(180/np.pi)\n",
    "c=torch.abs(ytestT[:,0,2]*(180/np.pi)- finalpred.data[:,0]*(180/np.pi))\n",
    "np.savetxt(\"pred.csv\", b.numpy(), delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"diff.csv\", c.numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalpred.data[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.misc import imresize, imread, imshow\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(9)\n",
    "fig.set_figwidth(9)\n",
    "import cv2\n",
    "\n",
    "test = cv2.imread(\"./Test_Net_image/4.JPG\")\n",
    "print(test.shape)\n",
    "test = imresize(test,(180,320,3))\n",
    "#imshow(test)\n",
    "test = test.transpose(2,0,1)\n",
    "test = np.reshape(test,(1,3,180,320))\n",
    "test = test.astype(np.float32)\n",
    "testPT = torch.from_numpy(test).float()\n",
    "testPT = batch_rgb_to_bgr(testPT)\n",
    "testPT = torch.div(testPT,255.0)\n",
    "mn = [0.406,0.456,0.485]\n",
    "sd = [0.225,0.224,0.229]\n",
    "norm = Normalize(mn,sd)\n",
    "testPT = norm(testPT)\n",
    "'''\n",
    "ind = 2000\n",
    "testPT = xtestT[ind]\n",
    "print(\"Actual angle===\"+str(ytestT[ind,0]*(180/np.pi)), ytestT[ind,0])\n",
    "testPT = testPT.view(1,3,180,320)\n",
    "#'''\n",
    "test_pred = net.forward(Variable(testPT, volatile=True).cuda())\n",
    "print(\"Angle===\"+str(test_pred.data[0,0]*(180/np.pi)), test_pred.data[0,0])\n",
    "testx = testPT.numpy()\n",
    "testx = np.reshape(testx,(3,180,320))\n",
    "testx = testx.transpose(1,2,0)\n",
    "testx = imresize(testx,(180,320,3))\n",
    "#imshow(testx)\n",
    "scipy.misc.imsave('test.png', testx)\n",
    "a=fig.add_subplot(1,2,1)\n",
    "imgplot = plt.imshow(testx)\n",
    "a.set_title('Input')\n",
    "a.axes.get_xaxis().set_visible(False)\n",
    "a.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
